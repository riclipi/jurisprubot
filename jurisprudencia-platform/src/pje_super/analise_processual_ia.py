"""
üß† AN√ÅLISE PROCESSUAL IA - EXTRA√á√ÉO AUTOM√ÅTICA INTELIGENTE
Sistema de IA para an√°lise e extra√ß√£o autom√°tica de informa√ß√µes processuais
"""

import re
import json
import asyncio
from typing import Dict, List, Optional, Any, Union, Tuple
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from enum import Enum
import logging
from pathlib import Path
import pandas as pd
import numpy as np

# OCR e processamento de texto
try:
    import pytesseract
    from PIL import Image
    import fitz  # PyMuPDF
    OCR_AVAILABLE = True
except ImportError:
    OCR_AVAILABLE = False

# NLP e IA
try:
    from sentence_transformers import SentenceTransformer
    import spacy
    NLP_AVAILABLE = True
except ImportError:
    NLP_AVAILABLE = False

class TipoDocumento(Enum):
    PETICAO_INICIAL = "peticao_inicial"
    CONTESTACAO = "contestacao"
    SENTENCA = "sentenca"
    DECISAO = "decisao"
    DESPACHO = "despacho"
    AC√ìRDAO = "acordao"
    RECURSO = "recurso"
    MANIFESTACAO = "manifestacao"
    DOCUMENTO_ANEXO = "documento_anexo"
    CERTIDAO = "certidao"
    OUTRO = "outro"

class StatusAnalise(Enum):
    PENDENTE = "pendente"
    PROCESSANDO = "processando"
    CONCLUIDA = "concluida"
    ERRO = "erro"
    PARCIAL = "parcial"

@dataclass
class EntidadeExtra√ß√£o:
    """Entidade extra√≠da do texto"""
    tipo: str
    valor: str
    confianca: float
    posicao_inicio: int
    posicao_fim: int
    contexto: str

@dataclass
class ParteProcessual:
    """Parte processual identificada"""
    nome: str
    tipo: str  # autor, reu, advogado, etc.
    documento: Optional[str] = None
    endereco: Optional[str] = None
    telefone: Optional[str] = None
    email: Optional[str] = None
    qualificacao: Optional[str] = None
    confianca: float = 0.0

@dataclass
class PedidoJudicial:
    """Pedido judicial extra√≠do"""
    descricao: str
    tipo: str  # principal, subsidiario, alternativo
    confianca: float = 0.0
    valor_monetario: Optional[str] = None
    fundamentacao: List[str] = field(default_factory=list)

@dataclass
class MovimentacaoProcessual:
    """Movimenta√ß√£o processual"""
    data: datetime
    tipo: str
    descricao: str
    codigo_cnj: Optional[str] = None
    responsavel: Optional[str] = None
    documento_gerado: Optional[str] = None
    metadados: Dict[str, Any] = field(default_factory=dict)

@dataclass
class AnaliseProcessualCompleta:
    """Resultado completo da an√°lise processual"""
    id_analise: str
    numero_processo: str
    data_analise: datetime
    
    # Informa√ß√µes b√°sicas
    classe_processual: Optional[str] = None
    assunto_principal: Optional[str] = None
    assuntos_secundarios: List[str] = field(default_factory=list)
    valor_causa: Optional[str] = None
    tribunal: Optional[str] = None
    comarca: Optional[str] = None
    vara: Optional[str] = None
    
    # Partes
    partes: List[ParteProcessual] = field(default_factory=list)
    
    # Pedidos
    pedidos: List[PedidoJudicial] = field(default_factory=list)
    
    # Movimenta√ß√µes
    movimentacoes: List[MovimentacaoProcessual] = field(default_factory=list)
    
    # Documentos analisados
    documentos_analisados: List[Dict] = field(default_factory=list)
    
    # Entidades extra√≠das
    entidades: List[EntidadeExtra√ß√£o] = field(default_factory=list)
    
    # An√°lise de sentimento e tend√™ncias
    sentimento_geral: Optional[str] = None
    probabilidade_sucesso: Optional[float] = None
    riscos_identificados: List[str] = field(default_factory=list)
    oportunidades: List[str] = field(default_factory=list)
    
    # Metadados
    tempo_processamento: Optional[float] = None
    confianca_geral: float = 0.0
    status: StatusAnalise = StatusAnalise.PENDENTE
    observacoes: List[str] = field(default_factory=list)

class AnaliseProcessualIA:
    """
    üß† SISTEMA DE AN√ÅLISE PROCESSUAL COM IA
    
    Funcionalidades avan√ßadas:
    - Extra√ß√£o autom√°tica de entidades jur√≠dicas
    - OCR inteligente para documentos escaneados
    - An√°lise de sentimento e tend√™ncias
    - Identifica√ß√£o autom√°tica de partes e pedidos
    - Classifica√ß√£o de documentos por tipo
    - Extra√ß√£o de movimenta√ß√µes processuais
    - An√°lise preditiva de resultados
    - Identifica√ß√£o de riscos e oportunidades
    """
    
    def __init__(self):
        self.setup_logging()
        self._inicializar_modelos()
        self._inicializar_patterns()
        self._inicializar_cache()
    
    def setup_logging(self):
        """Configura sistema de logs"""
        logging.basicConfig(level=logging.INFO)
        self.logger = logging.getLogger(__name__)
    
    def _inicializar_modelos(self):
        """Inicializa modelos de IA e NLP"""
        
        self.modelos_carregados = False
        
        try:
            if NLP_AVAILABLE:
                # Modelo de embeddings para an√°lise sem√¢ntica
                self.sentence_model = SentenceTransformer('all-MiniLM-L6-v2')
                
                # Modelo spaCy para NER em portugu√™s
                try:
                    self.nlp_model = spacy.load("pt_core_news_sm")
                except OSError:
                    self.logger.warning("Modelo spaCy pt_core_news_sm n√£o encontrado")
                    self.nlp_model = None
                
                self.modelos_carregados = True
                self.logger.info("Modelos de IA carregados com sucesso")
            else:
                self.logger.warning("Bibliotecas NLP n√£o dispon√≠veis - funcionalidade limitada")
        
        except Exception as e:
            self.logger.error(f"Erro ao carregar modelos: {e}")
    
    def _inicializar_patterns(self):
        """Inicializa padr√µes regex para extra√ß√£o"""
        
        # Padr√µes para CPF/CNPJ
        self.pattern_cpf = re.compile(r'\b\d{3}\.?\d{3}\.?\d{3}-?\d{2}\b')
        self.pattern_cnpj = re.compile(r'\b\d{2}\.?\d{3}\.?\d{3}/?\d{4}-?\d{2}\b')
        
        # Padr√µes para valores monet√°rios
        self.pattern_valor = re.compile(
            r'R\$\s*[\d.,]+|'
            r'reais?\s*[\d.,]+|'
            r'valor\s*de\s*R\$\s*[\d.,]+|'
            r'quantia\s*de\s*R\$\s*[\d.,]+|'
            r'import√¢ncia\s*de\s*R\$\s*[\d.,]+',
            re.IGNORECASE
        )
        
        # Padr√µes para datas
        self.pattern_data = re.compile(
            r'\b\d{1,2}[/.-]\d{1,2}[/.-]\d{2,4}\b|'
            r'\b\d{1,2}\s+de\s+\w+\s+de\s+\d{4}\b',
            re.IGNORECASE
        )
        
        # Padr√µes para endere√ßos
        self.pattern_endereco = re.compile(
            r'(?:rua|avenida|av|r\.|al\.|alameda|travessa|tv\.|pra√ßa|p√ßa)\s+[^,;.]+(?:,\s*\d+)?',
            re.IGNORECASE
        )
        
        # Padr√µes para emails
        self.pattern_email = re.compile(r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b')
        
        # Padr√µes para telefones
        self.pattern_telefone = re.compile(
            r'\(?\d{2}\)?\s*\d{4,5}[-.\s]?\d{4}|'
            r'\d{2}\s*\d{4,5}[-.\s]?\d{4}',
            re.IGNORECASE
        )
        
        # Padr√µes para n√∫meros de processo
        self.pattern_processo = re.compile(r'\b\d{7}-?\d{2}\.?\d{4}\.?\d{1}\.?\d{2}\.?\d{4}\b')
        
        # Padr√µes jur√≠dicos espec√≠ficos
        self.patterns_juridicos = {
            'artigo_lei': re.compile(r'art\.?\s*\d+[¬∫¬∞]?(?:,\s*¬ß\s*\d+[¬∫¬∞]?)?(?:,\s*inc\.?\s*[IVX]+)?', re.IGNORECASE),
            'codigo_legal': re.compile(r'(?:CC|CF|CDC|CPC|CLT|CP|CTN)\s*art\.?\s*\d+', re.IGNORECASE),
            'jurisprudencia': re.compile(r'(?:STF|STJ|TST|TRT|TRF|TJ)\s*[-,]?\s*\w+\s*\d+', re.IGNORECASE),
            'sumula': re.compile(r's√∫mula\s*(?:vinculante\s*)?\d+', re.IGNORECASE)
        }
        
        self.logger.info("Padr√µes regex inicializados")
    
    def _inicializar_cache(self):
        """Inicializa sistema de cache"""
        self.cache_analises = {}
        self.cache_extra√ß√µes = {}
        self.historico_analises = []
    
    async def analisar_processo_completo(self, 
                                       numero_processo: str,
                                       documentos: List[Dict],
                                       incluir_ocr: bool = True,
                                       incluir_nlp: bool = True) -> AnaliseProcessualCompleta:
        """
        üéØ AN√ÅLISE COMPLETA DO PROCESSO
        Executa an√°lise completa com IA
        """
        
        inicio = datetime.now()
        id_analise = f"analise_{numero_processo}_{int(inicio.timestamp())}"
        
        self.logger.info(f"Iniciando an√°lise completa: {numero_processo}")
        
        # Criar estrutura de an√°lise
        analise = AnaliseProcessualCompleta(
            id_analise=id_analise,
            numero_processo=numero_processo,
            data_analise=inicio,
            status=StatusAnalise.PROCESSANDO
        )
        
        try:
            # 1. Processar documentos
            await self._processar_documentos(analise, documentos, incluir_ocr)
            
            # 2. Extrair informa√ß√µes b√°sicas
            await self._extrair_informacoes_basicas(analise)
            
            # 3. Identificar partes processuais
            await self._identificar_partes(analise)
            
            # 4. Extrair pedidos judiciais
            await self._extrair_pedidos(analise)
            
            # 5. Analisar movimenta√ß√µes
            await self._analisar_movimentacoes(analise)
            
            # 6. An√°lise com NLP (se dispon√≠vel)
            if incluir_nlp and self.modelos_carregados:
                await self._analise_nlp_avancada(analise)
            
            # 7. An√°lise preditiva
            await self._analise_preditiva(analise)
            
            # 8. Calcular confian√ßa geral
            analise.confianca_geral = self._calcular_confianca_geral(analise)
            
            # Finalizar an√°lise
            fim = datetime.now()
            analise.tempo_processamento = (fim - inicio).total_seconds()
            analise.status = StatusAnalise.CONCLUIDA
            
            # Salvar no cache
            self.cache_analises[id_analise] = analise
            self.historico_analises.append({
                'id': id_analise,
                'numero_processo': numero_processo,
                'timestamp': inicio,
                'tempo_processamento': analise.tempo_processamento
            })
            
            self.logger.info(f"An√°lise conclu√≠da: {numero_processo} em {analise.tempo_processamento:.2f}s")
            return analise
            
        except Exception as e:
            analise.status = StatusAnalise.ERRO
            analise.observacoes.append(f"Erro na an√°lise: {str(e)}")
            self.logger.error(f"Erro na an√°lise: {e}")
            return analise
    
    async def _processar_documentos(self, analise: AnaliseProcessualCompleta, 
                                  documentos: List[Dict], incluir_ocr: bool):
        """Processa documentos do processo"""
        
        self.logger.info(f"Processando {len(documentos)} documentos")
        
        for doc_info in documentos:
            try:
                doc_processado = {
                    'nome': doc_info.get('nome', ''),
                    'tipo': doc_info.get('tipo', ''),
                    'caminho': doc_info.get('caminho', ''),
                    'texto_extraido': '',
                    'tipo_detectado': TipoDocumento.OUTRO,
                    'metadados': {}
                }
                
                # Extrair texto
                if doc_info.get('caminho'):
                    texto = await self._extrair_texto_documento(doc_info['caminho'], incluir_ocr)
                    doc_processado['texto_extraido'] = texto
                elif doc_info.get('conteudo'):
                    doc_processado['texto_extraido'] = doc_info['conteudo']
                
                # Detectar tipo do documento
                if doc_processado['texto_extraido']:
                    doc_processado['tipo_detectado'] = self._detectar_tipo_documento(doc_processado['texto_extraido'])
                
                analise.documentos_analisados.append(doc_processado)
                
            except Exception as e:
                self.logger.error(f"Erro ao processar documento {doc_info.get('nome', '')}: {e}")
    
    async def _extrair_texto_documento(self, caminho: str, incluir_ocr: bool) -> str:
        """Extrai texto de documento"""
        
        caminho_path = Path(caminho)
        if not caminho_path.exists():
            return ""
        
        texto = ""
        extensao = caminho_path.suffix.lower()
        
        try:
            if extensao == '.pdf':
                # Extrair texto de PDF
                doc = fitz.open(caminho)
                for page in doc:
                    texto += page.get_text()
                doc.close()
                
                # Se n√£o extraiu texto e OCR est√° habilitado
                if not texto.strip() and incluir_ocr and OCR_AVAILABLE:
                    texto = await self._ocr_pdf(caminho)
                    
            elif extensao in ['.jpg', '.jpeg', '.png', '.tiff'] and incluir_ocr and OCR_AVAILABLE:
                # OCR em imagens
                texto = await self._ocr_imagem(caminho)
                
            elif extensao == '.txt':
                # Arquivo texto
                with open(caminho, 'r', encoding='utf-8') as f:
                    texto = f.read()
                    
        except Exception as e:
            self.logger.error(f"Erro ao extrair texto de {caminho}: {e}")
        
        return texto
    
    async def _ocr_pdf(self, caminho: str) -> str:
        """OCR em PDF"""
        try:
            doc = fitz.open(caminho)
            texto_completo = ""
            
            for page_num in range(min(10, len(doc))):  # Limitar a 10 p√°ginas
                page = doc[page_num]
                pix = page.get_pixmap()
                img_data = pix.tobytes("png")
                
                # Converter para PIL Image
                from io import BytesIO
                img = Image.open(BytesIO(img_data))
                
                # OCR
                texto_pagina = pytesseract.image_to_string(img, lang='por')
                texto_completo += texto_pagina + "\n"
            
            doc.close()
            return texto_completo
            
        except Exception as e:
            self.logger.error(f"Erro no OCR do PDF: {e}")
            return ""
    
    async def _ocr_imagem(self, caminho: str) -> str:
        """OCR em imagem"""
        try:
            img = Image.open(caminho)
            texto = pytesseract.image_to_string(img, lang='por')
            return texto
        except Exception as e:
            self.logger.error(f"Erro no OCR da imagem: {e}")
            return ""
    
    def _detectar_tipo_documento(self, texto: str) -> TipoDocumento:
        """Detecta tipo do documento pelo conte√∫do"""
        
        texto_lower = texto.lower()
        
        # Padr√µes para identifica√ß√£o
        if any(word in texto_lower for word in ['peti√ß√£o inicial', 'excelent√≠ssimo', 'vem respeitosamente']):
            return TipoDocumento.PETICAO_INICIAL
        elif any(word in texto_lower for word in ['contesta√ß√£o', 'impugna√ß√£o', 'defesa']):
            return TipoDocumento.CONTESTACAO
        elif any(word in texto_lower for word in ['senten√ßa', 'julgo procedente', 'julgo improcedente']):
            return TipoDocumento.SENTENCA
        elif any(word in texto_lower for word in ['ac√≥rd√£o', 'tribunal', 'recurso conhecido']):
            return TipoDocumento.AC√ìRDAO
        elif any(word in texto_lower for word in ['decis√£o', 'defiro', 'indefiro']):
            return TipoDocumento.DECISAO
        elif any(word in texto_lower for word in ['despacho', 'intimem-se', 'cumpra-se']):
            return TipoDocumento.DESPACHO
        elif any(word in texto_lower for word in ['recurso', 'apela√ß√£o', 'agravo']):
            return TipoDocumento.RECURSO
        elif any(word in texto_lower for word in ['certid√£o', 'certifico']):
            return TipoDocumento.CERTIDAO
        else:
            return TipoDocumento.OUTRO
    
    async def _extrair_informacoes_basicas(self, analise: AnaliseProcessualCompleta):
        """Extrai informa√ß√µes b√°sicas do processo"""
        
        texto_completo = self._obter_texto_completo(analise)
        
        # Extrair classe processual
        analise.classe_processual = self._extrair_classe_processual(texto_completo)
        
        # Extrair assunto principal
        analise.assunto_principal = self._extrair_assunto_principal(texto_completo)
        
        # Extrair valor da causa
        analise.valor_causa = self._extrair_valor_causa(texto_completo)
        
        # Extrair tribunal/comarca
        analise.tribunal = self._extrair_tribunal(texto_completo)
        analise.comarca = self._extrair_comarca(texto_completo)
        
        self.logger.info("Informa√ß√µes b√°sicas extra√≠das")
    
    async def _identificar_partes(self, analise: AnaliseProcessualCompleta):
        """Identifica partes processuais"""
        
        texto_completo = self._obter_texto_completo(analise)
        
        # Padr√µes para identificar partes
        patterns_partes = {
            'autor': re.compile(r'(?:autor|requerente|impetrante).*?:?\s*([^,;\n]+)', re.IGNORECASE),
            'reu': re.compile(r'(?:r√©u|requerido|impetrado).*?:?\s*([^,;\n]+)', re.IGNORECASE),
            'advogado': re.compile(r'(?:advogado|dr\.|dra\.).*?([^,;\n]+)', re.IGNORECASE)
        }
        
        for tipo, pattern in patterns_partes.items():
            matches = pattern.findall(texto_completo)
            for match in matches[:5]:  # Limitar a 5 por tipo
                nome = match.strip()
                if len(nome) > 3:  # Nome m√≠nimo
                    parte = ParteProcessual(
                        nome=nome,
                        tipo=tipo,
                        confianca=0.7
                    )
                    
                    # Extrair documento se poss√≠vel
                    parte.documento = self._extrair_documento_parte(texto_completo, nome)
                    
                    analise.partes.append(parte)
        
        self.logger.info(f"Identificadas {len(analise.partes)} partes")
    
    async def _extrair_pedidos(self, analise: AnaliseProcessualCompleta):
        """Extrai pedidos judiciais"""
        
        texto_completo = self._obter_texto_completo(analise)
        
        # Padr√µes para pedidos
        pattern_pedidos = re.compile(
            r'(?:requer|pede|postula|pleiteia).*?(?:que|a\s*v\.?\s*ex[a¬™]\.?).*?([^;.\n]+)',
            re.IGNORECASE | re.DOTALL
        )
        
        matches = pattern_pedidos.findall(texto_completo)
        for match in matches[:10]:  # Limitar a 10 pedidos
            pedido_texto = match.strip()
            if len(pedido_texto) > 10:
                pedido = PedidoJudicial(
                    descricao=pedido_texto,
                    tipo='principal',
                    valor_monetario=self._extrair_valor_do_texto(pedido_texto),
                    confianca=0.6
                )
                analise.pedidos.append(pedido)
        
        self.logger.info(f"Extra√≠dos {len(analise.pedidos)} pedidos")
    
    async def _analisar_movimentacoes(self, analise: AnaliseProcessualCompleta):
        """Analisa movimenta√ß√µes processuais"""
        
        # Implementa√ß√£o b√°sica - em produ√ß√£o integraria com dados do tribunal
        texto_completo = self._obter_texto_completo(analise)
        
        # Padr√£o para datas de movimenta√ß√£o
        pattern_mov = re.compile(
            r'(\d{1,2}[/.-]\d{1,2}[/.-]\d{2,4})\s*[-:]?\s*([^.\n]{10,100})',
            re.IGNORECASE
        )
        
        matches = pattern_mov.findall(texto_completo)
        for data_str, descricao in matches[:20]:  # Limitar a 20
            try:
                data = self._parse_data(data_str)
                if data:
                    mov = MovimentacaoProcessual(
                        data=data,
                        tipo='movimentacao_geral',
                        descricao=descricao.strip()
                    )
                    analise.movimentacoes.append(mov)
            except:
                continue
        
        self.logger.info(f"Analisadas {len(analise.movimentacoes)} movimenta√ß√µes")
    
    async def _analise_nlp_avancada(self, analise: AnaliseProcessualCompleta):
        """An√°lise avan√ßada com NLP"""
        
        if not self.modelos_carregados:
            return
        
        texto_completo = self._obter_texto_completo(analise)
        
        try:
            # An√°lise de entidades com spaCy
            if self.nlp_model:
                doc = self.nlp_model(texto_completo[:1000000])  # Limitar tamanho
                
                for ent in doc.ents:
                    entidade = EntidadeExtra√ß√£o(
                        tipo=ent.label_,
                        valor=ent.text,
                        confianca=0.8,
                        posicao_inicio=ent.start_char,
                        posicao_fim=ent.end_char,
                        contexto=texto_completo[max(0, ent.start_char-50):ent.end_char+50]
                    )
                    analise.entidades.append(entidade)
            
            # An√°lise de sentimento b√°sica
            analise.sentimento_geral = self._analisar_sentimento(texto_completo)
            
            self.logger.info("An√°lise NLP avan√ßada conclu√≠da")
            
        except Exception as e:
            self.logger.error(f"Erro na an√°lise NLP: {e}")
    
    async def _analise_preditiva(self, analise: AnaliseProcessualCompleta):
        """An√°lise preditiva de resultados"""
        
        # An√°lise b√°sica baseada em padr√µes
        texto_completo = self._obter_texto_completo(analise).lower()
        
        # Fatores positivos
        fatores_positivos = [
            'jurisprud√™ncia consolidada', 'precedente favor√°vel', 's√∫mula',
            'dano evidente', 'prova cabal', 'documentos comprobat√≥rios'
        ]
        
        # Fatores negativos
        fatores_negativos = [
            'falta de provas', 'jurisprud√™ncia contr√°ria', 'prescri√ß√£o',
            'decad√™ncia', 'car√™ncia de a√ß√£o'
        ]
        
        score_positivo = sum(1 for fator in fatores_positivos if fator in texto_completo)
        score_negativo = sum(1 for fator in fatores_negativos if fator in texto_completo)
        
        # Calcular probabilidade b√°sica
        if score_positivo + score_negativo > 0:
            analise.probabilidade_sucesso = score_positivo / (score_positivo + score_negativo)
        else:
            analise.probabilidade_sucesso = 0.5  # Neutro
        
        # Identificar riscos
        if 'prescri√ß√£o' in texto_completo:
            analise.riscos_identificados.append("Poss√≠vel prescri√ß√£o da a√ß√£o")
        if 'falta de provas' in texto_completo:
            analise.riscos_identificados.append("Insufici√™ncia de provas")
        
        # Identificar oportunidades
        if 's√∫mula' in texto_completo:
            analise.oportunidades.append("S√∫mula favor√°vel identificada")
        if 'precedente' in texto_completo:
            analise.oportunidades.append("Precedentes favor√°veis")
        
        self.logger.info("An√°lise preditiva conclu√≠da")
    
    # M√âTODOS AUXILIARES
    
    def _obter_texto_completo(self, analise: AnaliseProcessualCompleta) -> str:
        """Obt√©m texto completo de todos os documentos"""
        return "\n\n".join([doc['texto_extraido'] for doc in analise.documentos_analisados])
    
    def _extrair_classe_processual(self, texto: str) -> Optional[str]:
        """Extrai classe processual"""
        patterns = [
            r'(?:classe|a√ß√£o|processo)\s*(?:de\s*)?([^,;\n]{5,50})',
            r'(?:a√ß√£o|procedimento)\s+([^,;\n]{5,50})'
        ]
        
        for pattern in patterns:
            match = re.search(pattern, texto, re.IGNORECASE)
            if match:
                return match.group(1).strip()
        return None
    
    def _extrair_assunto_principal(self, texto: str) -> Optional[str]:
        """Extrai assunto principal"""
        patterns = [
            r'(?:assunto|mat√©ria|objeto).*?:?\s*([^,;\n]{10,100})',
            r'(?:trata-se|cuida-se)\s+de\s+([^,;\n]{10,100})'
        ]
        
        for pattern in patterns:
            match = re.search(pattern, texto, re.IGNORECASE)
            if match:
                return match.group(1).strip()
        return None
    
    def _extrair_valor_causa(self, texto: str) -> Optional[str]:
        """Extrai valor da causa"""
        patterns = [
            r'valor\s*da\s*causa.*?R\$\s*([\d.,]+)',
            r'valor\s*atribu√≠do.*?R\$\s*([\d.,]+)',
            r'd√°-se\s*√†\s*causa.*?R\$\s*([\d.,]+)'
        ]
        
        for pattern in patterns:
            match = re.search(pattern, texto, re.IGNORECASE)
            if match:
                return f"R$ {match.group(1)}"
        return None
    
    def _extrair_tribunal(self, texto: str) -> Optional[str]:
        """Extrai tribunal"""
        tribunais = ['STF', 'STJ', 'TST', 'TRF', 'TRT', 'TJSP', 'TJRJ', 'TJMG', 'TJRS']
        
        for tribunal in tribunais:
            if tribunal in texto.upper():
                return tribunal
        return None
    
    def _extrair_comarca(self, texto: str) -> Optional[str]:
        """Extrai comarca"""
        pattern = r'comarca\s*de\s*([^,;\n]{3,50})'
        match = re.search(pattern, texto, re.IGNORECASE)
        return match.group(1).strip() if match else None
    
    def _extrair_documento_parte(self, texto: str, nome: str) -> Optional[str]:
        """Extrai documento da parte"""
        # Buscar CPF/CNPJ pr√≥ximo ao nome
        nome_pos = texto.find(nome)
        if nome_pos != -1:
            contexto = texto[nome_pos:nome_pos+500]
            
            cpf_match = self.pattern_cpf.search(contexto)
            if cpf_match:
                return cpf_match.group()
            
            cnpj_match = self.pattern_cnpj.search(contexto)
            if cnpj_match:
                return cnpj_match.group()
        
        return None
    
    def _extrair_valor_do_texto(self, texto: str) -> Optional[str]:
        """Extrai valor monet√°rio do texto"""
        match = self.pattern_valor.search(texto)
        return match.group() if match else None
    
    def _parse_data(self, data_str: str) -> Optional[datetime]:
        """Converte string em datetime"""
        formats = ['%d/%m/%Y', '%d-%m-%Y', '%d.%m.%Y']
        
        for fmt in formats:
            try:
                return datetime.strptime(data_str, fmt)
            except ValueError:
                continue
        return None
    
    def _analisar_sentimento(self, texto: str) -> str:
        """An√°lise b√°sica de sentimento"""
        palavras_positivas = ['procedente', 'deferido', 'favor√°vel', 'sucesso', 'ganho']
        palavras_negativas = ['improcedente', 'indeferido', 'desfavor√°vel', 'perda', 'negado']
        
        texto_lower = texto.lower()
        score_pos = sum(1 for palavra in palavras_positivas if palavra in texto_lower)
        score_neg = sum(1 for palavra in palavras_negativas if palavra in texto_lower)
        
        if score_pos > score_neg:
            return "positivo"
        elif score_neg > score_pos:
            return "negativo"
        else:
            return "neutro"
    
    def _calcular_confianca_geral(self, analise: AnaliseProcessualCompleta) -> float:
        """Calcula confian√ßa geral da an√°lise"""
        
        scores = []
        
        # Score baseado na quantidade de informa√ß√µes extra√≠das
        if analise.classe_processual:
            scores.append(0.8)
        if analise.partes:
            scores.append(0.9)
        if analise.pedidos:
            scores.append(0.7)
        if analise.valor_causa:
            scores.append(0.6)
        
        # Score baseado na qualidade dos documentos
        docs_com_texto = len([d for d in analise.documentos_analisados if d['texto_extraido']])
        if docs_com_texto > 0:
            scores.append(min(1.0, docs_com_texto / len(analise.documentos_analisados)))
        
        return np.mean(scores) if scores else 0.3
    
    # M√âTODOS P√öBLICOS
    
    def obter_estatisticas(self) -> Dict[str, Any]:
        """Obt√©m estat√≠sticas do sistema"""
        
        return {
            'total_analises': len(self.historico_analises),
            'analises_em_cache': len(self.cache_analises),
            'modelos_carregados': self.modelos_carregados,
            'ocr_disponivel': OCR_AVAILABLE,
            'nlp_disponivel': NLP_AVAILABLE,
            'tempo_medio_processamento': np.mean([
                a['tempo_processamento'] for a in self.historico_analises 
                if a.get('tempo_processamento')
            ]) if self.historico_analises else 0
        }

# Fun√ß√£o de conveni√™ncia
async def analisar_processo_ia(numero_processo: str, 
                             documentos: List[Dict]) -> AnaliseProcessualCompleta:
    """
    üß† FUN√á√ÉO DE CONVENI√äNCIA
    An√°lise r√°pida de processo com IA
    """
    analisador = AnaliseProcessualIA()
    return await analisador.analisar_processo_completo(numero_processo, documentos)

# Exemplo de uso
if __name__ == "__main__":
    async def testar_analise_ia():
        """üß™ TESTE DA AN√ÅLISE PROCESSUAL IA"""
        
        print("üß† TESTANDO AN√ÅLISE PROCESSUAL IA")
        print("=" * 60)
        
        analisador = AnaliseProcessualIA()
        
        # Documentos de teste
        documentos_teste = [
            {
                'nome': 'peti√ß√£o_inicial.txt',
                'tipo': 'peticao_inicial',
                'conteudo': """
                EXCELENT√çSSIMO SENHOR DOUTOR JUIZ DE DIREITO DA VARA C√çVEL
                
                JO√ÉO DA SILVA, brasileiro, solteiro, engenheiro, portador do CPF 123.456.789-00,
                residente e domiciliado na Rua das Flores, 123, S√£o Paulo/SP,
                
                vem respeitosamente √† presen√ßa de Vossa Excel√™ncia propor
                
                A√á√ÉO DE INDENIZA√á√ÉO POR DANOS MORAIS
                
                em face de BANCO PREMIUM S.A., pessoa jur√≠dica de direito privado,
                CNPJ 12.345.678/0001-99, pelos motivos de fato e de direito que passa a expor:
                
                I - DOS FATOS
                O autor teve seu nome negativado indevidamente pelo r√©u.
                
                II - DOS PEDIDOS
                Requer a condena√ß√£o do r√©u ao pagamento de R$ 15.000,00 a t√≠tulo de danos morais.
                
                D√°-se √† causa o valor de R$ 15.000,00.
                """
            }
        ]
        
        # Executar an√°lise
        print("üîç Executando an√°lise...")
        analise = await analisador.analisar_processo_completo(
            "1234567-89.2023.8.26.0001",
            documentos_teste
        )
        
        # Exibir resultados
        print(f"\nüìã RESULTADOS DA AN√ÅLISE")
        print("-" * 40)
        print(f"Status: {analise.status.value}")
        print(f"Confian√ßa geral: {analise.confianca_geral:.1%}")
        print(f"Tempo processamento: {analise.tempo_processamento:.2f}s")
        
        if analise.classe_processual:
            print(f"Classe: {analise.classe_processual}")
        if analise.valor_causa:
            print(f"Valor da causa: {analise.valor_causa}")
        
        print(f"\nüë• PARTES ({len(analise.partes)})")
        for parte in analise.partes:
            print(f"  ‚Ä¢ {parte.tipo}: {parte.nome}")
            if parte.documento:
                print(f"    Doc: {parte.documento}")
        
        print(f"\nüìù PEDIDOS ({len(analise.pedidos)})")
        for pedido in analise.pedidos:
            print(f"  ‚Ä¢ {pedido.tipo}: {pedido.descricao[:80]}...")
            if pedido.valor_monetario:
                print(f"    Valor: {pedido.valor_monetario}")
        
        if analise.probabilidade_sucesso is not None:
            print(f"\nüìä AN√ÅLISE PREDITIVA")
            print(f"Probabilidade sucesso: {analise.probabilidade_sucesso:.1%}")
        
        if analise.riscos_identificados:
            print(f"Riscos: {len(analise.riscos_identificados)}")
        if analise.oportunidades:
            print(f"Oportunidades: {len(analise.oportunidades)}")
        
        # Estat√≠sticas do sistema
        print(f"\nüìà ESTAT√çSTICAS DO SISTEMA")
        stats = analisador.obter_estatisticas()
        print(f"Modelos carregados: {stats['modelos_carregados']}")
        print(f"OCR dispon√≠vel: {stats['ocr_disponivel']}")
        print(f"NLP dispon√≠vel: {stats['nlp_disponivel']}")
        
        print(f"\nüéâ TESTE CONCLU√çDO!")
        print("üß† AN√ÅLISE PROCESSUAL IA FUNCIONAL!")
    
    # Executar teste
    asyncio.run(testar_analise_ia())