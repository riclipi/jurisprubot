{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimentos - Plataforma de Jurisprudência\n",
    "\n",
    "Este notebook contém experimentos e testes para a plataforma de jurisprudência."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup Inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Adiciona o diretório raiz ao path\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "\n",
    "# Imports\n",
    "from src.scraper.tjsp_scraper import TJSPScraper\n",
    "from src.processing.pdf_processor import PDFProcessor\n",
    "from src.processing.text_chunker import TextChunker\n",
    "from src.rag.embeddings import EmbeddingsManager\n",
    "from src.rag.search_engine import JurisprudenceSearchEngine\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configurações de visualização\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Teste do Scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializa o scraper\n",
    "scraper = TJSPScraper()\n",
    "\n",
    "# Busca simples\n",
    "query = \"contrato de locação inadimplemento\"\n",
    "print(f\"Buscando por: {query}\")\n",
    "\n",
    "# Realiza busca (sem download)\n",
    "results = scraper.search_jurisprudence(query, max_results=5)\n",
    "\n",
    "# Mostra resultados\n",
    "for i, result in enumerate(results):\n",
    "    print(f\"\\n--- Resultado {i+1} ---\")\n",
    "    print(f\"Processo: {result.get('case_number', 'N/A')}\")\n",
    "    print(f\"Data: {result.get('judgment_date', 'N/A')}\")\n",
    "    print(f\"Tribunal: {result.get('court', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Teste de Processamento de PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializa o processador\n",
    "processor = PDFProcessor()\n",
    "\n",
    "# Lista PDFs disponíveis\n",
    "pdf_files = list(processor.raw_dir.glob(\"*.pdf\"))\n",
    "print(f\"PDFs encontrados: {len(pdf_files)}\")\n",
    "\n",
    "if pdf_files:\n",
    "    # Processa o primeiro PDF\n",
    "    pdf_path = pdf_files[0]\n",
    "    print(f\"\\nProcessando: {pdf_path.name}\")\n",
    "    \n",
    "    result = processor.process_pdf(pdf_path)\n",
    "    \n",
    "    if result:\n",
    "        print(\"\\nMetadados extraídos:\")\n",
    "        for key, value in result['metadata'].items():\n",
    "            print(f\"  {key}: {value}\")\n",
    "        \n",
    "        print(f\"\\nTexto extraído (primeiros 500 caracteres):\")\n",
    "        print(result['cleaned_text'][:500] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Teste de Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializa o chunker\n",
    "chunker = TextChunker(chunk_size=500, chunk_overlap=50)\n",
    "\n",
    "# Texto de exemplo\n",
    "sample_text = \"\"\"\n",
    "ACÓRDÃO\n",
    "\n",
    "Vistos, relatados e discutidos estes autos de Apelação Cível nº 1234567-89.2023.8.26.0100,\n",
    "da Comarca de São Paulo, em que é apelante JOÃO DA SILVA, é apelado MARIA DOS SANTOS.\n",
    "\n",
    "ACORDAM, em 5ª Câmara de Direito Privado do Tribunal de Justiça de São Paulo,\n",
    "proferir a seguinte decisão: \"Negaram provimento ao recurso. V.U.\", de conformidade\n",
    "com o voto do Relator, que integra este acórdão.\n",
    "\n",
    "O julgamento teve a participação dos Exmos. Desembargadores MOREIRA VIEGAS (Presidente),\n",
    "JAMES SIANO E FERNANDA GOMES CAMACHO.\n",
    "\n",
    "São Paulo, 15 de março de 2023.\n",
    "\n",
    "MOREIRA VIEGAS\n",
    "RELATOR\n",
    "\"\"\"\n",
    "\n",
    "# Cria chunks\n",
    "chunks = chunker.chunk_text(sample_text, metadata={'case_number': '1234567-89.2023.8.26.0100'})\n",
    "\n",
    "print(f\"Número de chunks criados: {len(chunks)}\")\n",
    "print(\"\\nChunks:\")\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"\\n--- Chunk {i+1} ---\")\n",
    "    print(f\"Tamanho: {len(chunk.page_content)} caracteres\")\n",
    "    print(f\"Conteúdo: {chunk.page_content[:100]}...\")\n",
    "    print(f\"Metadados: {chunk.metadata}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Teste de Embeddings e Busca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializa o gerenciador de embeddings\n",
    "embeddings_manager = EmbeddingsManager()\n",
    "\n",
    "# Cria documentos de exemplo\n",
    "from langchain.schema import Document\n",
    "\n",
    "sample_docs = [\n",
    "    Document(\n",
    "        page_content=\"Trata-se de ação de cobrança referente a contrato de locação comercial inadimplido.\",\n",
    "        metadata={\"case_number\": \"111111\", \"type\": \"cobrança\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Ação de despejo por falta de pagamento de aluguéis vencidos.\",\n",
    "        metadata={\"case_number\": \"222222\", \"type\": \"despejo\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Contrato de compra e venda de imóvel com cláusula de retrovenda.\",\n",
    "        metadata={\"case_number\": \"333333\", \"type\": \"compra_venda\"}\n",
    "    ),\n",
    "]\n",
    "\n",
    "# Adiciona documentos\n",
    "print(\"Adicionando documentos ao vector store...\")\n",
    "ids = embeddings_manager.add_documents(sample_docs)\n",
    "print(f\"Documentos adicionados com IDs: {ids}\")\n",
    "\n",
    "# Teste de busca\n",
    "query = \"contrato de aluguel não pago\"\n",
    "print(f\"\\nBuscando por: '{query}'\")\n",
    "\n",
    "results = embeddings_manager.search(query, k=3)\n",
    "\n",
    "print(\"\\nResultados:\")\n",
    "for i, result in enumerate(results):\n",
    "    print(f\"\\n{i+1}. Score: {1 - result['distance']:.3f}\")\n",
    "    print(f\"   Conteúdo: {result['content']}\")\n",
    "    print(f\"   Metadados: {result['metadata']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Teste do Search Engine com RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializa o search engine\n",
    "# Nota: Certifique-se de ter configurado a API key\n",
    "try:\n",
    "    search_engine = JurisprudenceSearchEngine(llm_provider=\"openai\")\n",
    "    \n",
    "    # Pergunta de teste\n",
    "    question = \"Quais são os requisitos para uma ação de despejo?\"\n",
    "    print(f\"Pergunta: {question}\")\n",
    "    \n",
    "    # Busca resposta\n",
    "    response = search_engine.answer_question(question, k=3)\n",
    "    \n",
    "    print(\"\\nResposta:\")\n",
    "    print(response['answer'])\n",
    "    \n",
    "    print(\"\\nFontes consultadas:\")\n",
    "    for i, source in enumerate(response['sources']):\n",
    "        print(f\"\\n{i+1}. {source['metadata']}\")\n",
    "        print(f\"   {source['content']}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Erro ao inicializar search engine: {e}\")\n",
    "    print(\"Verifique se a API key está configurada no arquivo .env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Análise de Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Teste de performance de embedding\n",
    "test_texts = [\n",
    "    \"Contrato de locação residencial\",\n",
    "    \"Ação de cobrança por inadimplemento contratual\",\n",
    "    \"Recurso de apelação em ação de despejo\",\n",
    "    \"Sentença procedente em ação de danos morais\",\n",
    "    \"Acordo judicial homologado pelo juízo\"\n",
    "]\n",
    "\n",
    "# Mede tempo de embedding\n",
    "print(\"Testando performance de embeddings...\")\n",
    "times = []\n",
    "\n",
    "for text in test_texts:\n",
    "    start = time.time()\n",
    "    embedding = embeddings_manager.embed_query(text)\n",
    "    end = time.time()\n",
    "    times.append(end - start)\n",
    "    print(f\"'{text[:30]}...' - {(end-start)*1000:.2f}ms\")\n",
    "\n",
    "print(f\"\\nTempo médio: {sum(times)/len(times)*1000:.2f}ms\")\n",
    "print(f\"Dimensão do embedding: {len(embedding)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Visualização de Similaridades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Textos para comparar\n",
    "texts = [\n",
    "    \"Contrato de locação comercial inadimplido\",\n",
    "    \"Ação de despejo por falta de pagamento\",\n",
    "    \"Contrato de compra e venda de imóvel\",\n",
    "    \"Recurso de apelação em matéria criminal\",\n",
    "    \"Habeas corpus preventivo\"\n",
    "]\n",
    "\n",
    "# Gera embeddings\n",
    "embeddings = [embeddings_manager.embed_query(text) for text in texts]\n",
    "embeddings_array = np.array(embeddings)\n",
    "\n",
    "# Calcula matriz de similaridade\n",
    "similarity_matrix = cosine_similarity(embeddings_array)\n",
    "\n",
    "# Visualiza\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(similarity_matrix, \n",
    "            xticklabels=[t[:20] + \"...\" for t in texts],\n",
    "            yticklabels=[t[:20] + \"...\" for t in texts],\n",
    "            annot=True, \n",
    "            fmt=\".2f\",\n",
    "            cmap=\"YlOrRd\")\n",
    "plt.title(\"Matriz de Similaridade entre Documentos\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Estatísticas da Base de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtém estatísticas\n",
    "stats = embeddings_manager.get_collection_stats()\n",
    "\n",
    "print(\"=== Estatísticas da Base de Dados ===\")\n",
    "for key, value in stats.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "# Conta arquivos\n",
    "from config.settings import RAW_PDF_DIR, PROCESSED_DIR\n",
    "\n",
    "pdf_count = len(list(RAW_PDF_DIR.glob(\"*.pdf\")))\n",
    "processed_count = len(list(PROCESSED_DIR.glob(\"*.json\")))\n",
    "\n",
    "print(f\"\\nPDFs baixados: {pdf_count}\")\n",
    "print(f\"Documentos processados: {processed_count}\")\n",
    "\n",
    "# Gráfico de barras\n",
    "data = {\n",
    "    'PDFs': pdf_count,\n",
    "    'Processados': processed_count,\n",
    "    'Vetorizados': stats['document_count']\n",
    "}\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(data.keys(), data.values(), color=['#1f77b4', '#ff7f0e', '#2ca02c'])\n",
    "plt.title('Status do Pipeline de Processamento')\n",
    "plt.ylabel('Quantidade')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Exemplo Completo - Pipeline End-to-End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline completo de exemplo\n",
    "print(\"=== PIPELINE COMPLETO ===\")\n",
    "\n",
    "# 1. Busca\n",
    "print(\"\\n1. BUSCA NO TJSP\")\n",
    "query = \"danos morais consumidor\"\n",
    "print(f\"Buscando: {query}\")\n",
    "\n",
    "# Simula busca (em produção, usar scraper.scrape_and_download)\n",
    "print(\"[Simulado] 3 documentos encontrados\")\n",
    "\n",
    "# 2. Processamento\n",
    "print(\"\\n2. PROCESSAMENTO DE TEXTO\")\n",
    "sample_text = \"\"\"\n",
    "EMENTA: PRESTAÇÃO DE SERVIÇOS - INDENIZAÇÃO POR DANOS MORAIS - \n",
    "Falha na prestação de serviços - Responsabilidade objetiva do fornecedor - \n",
    "Dano moral configurado - Quantum indenizatório fixado em R$ 5.000,00 - \n",
    "Sentença mantida - Recurso não provido.\n",
    "\"\"\"\n",
    "\n",
    "# 3. Chunking\n",
    "print(\"\\n3. CHUNKING\")\n",
    "chunks = chunker.chunk_text(sample_text, {'case_number': 'EXEMPLO-001'})\n",
    "print(f\"Criados {len(chunks)} chunks\")\n",
    "\n",
    "# 4. Indexação\n",
    "print(\"\\n4. INDEXAÇÃO VETORIAL\")\n",
    "ids = embeddings_manager.add_documents(chunks)\n",
    "print(f\"Indexados com IDs: {ids}\")\n",
    "\n",
    "# 5. Busca semântica\n",
    "print(\"\\n5. BUSCA SEMÂNTICA\")\n",
    "search_query = \"indenização por falha no serviço\"\n",
    "results = embeddings_manager.search(search_query, k=1)\n",
    "\n",
    "if results:\n",
    "    print(f\"Melhor resultado (score: {1 - results[0]['distance']:.3f}):\")\n",
    "    print(results[0]['content'])\n",
    "\n",
    "print(\"\\n=== PIPELINE CONCLUÍDO ===\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}